{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRML Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes from class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT language model is an open source machine learning framework for natural language processing (NLP). BERT is designed to help computers understand the meaning of ambiguous language in text by using surrounding text to establish context.\n",
    "\n",
    "Try to download BERT and check it out???\n",
    "- Give it data about UC or the environment\n",
    "- It's airgapped lol\n",
    "- Give it extra data to fine tune \n",
    "\n",
    "AI and ML is all about patterns.\n",
    "Patterns in data\n",
    "Detect \n",
    "\n",
    "In order to predict we need to recognise a pattern.\n",
    "\n",
    "Predict the sale price of a house.\n",
    "Block size, bathrooms, age, rooms, suburb\n",
    "\n",
    "Pattern recognition will find patterns \n",
    "Babies start recognising patterns\n",
    "\n",
    "Pattern Rec. is first\n",
    "ML is next - is this a banana?\n",
    "\n",
    "GPT is trained on text data. \n",
    "\n",
    "BERT will learn the pattern in the data\n",
    "Then BERT can do the task, answer the question\n",
    "\n",
    "Clustering - clustering items together \n",
    "eg: Amazon purchase - here's a mouse and keyboard as well\n",
    "\n",
    "Fitting a polynomial to X ? \n",
    "y = 2x\n",
    "\n",
    "Fit a function to learn the relationship.\n",
    "\n",
    "What is a polynomial function?\n",
    "\n",
    "f(x) of the something tool \n",
    "\n",
    "polynomial of the third degree?\n",
    "\n",
    "x1 and x2, what would my polynomial look like?\n",
    "\n",
    "a x1^2 + b x2^2 # TODO lol\n",
    "\n",
    "polynomial features to process your data, then use a linear equation.\n",
    "\n",
    "Inverse square law - lamp and brightness, measured 2m away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What are Ensembles?\n",
    "- Ensembles of Decision Trees\n",
    "- Combining multiple methods of machine learning models for more power \n",
    "- Two powerful methods both use Decision Trees:\n",
    "  - Random Forests\n",
    "  - Gradient Boosted Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Trace of a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The trace is also equal to the sum of the eigenvalues of the matrix, with each eigenvalue counted as many times as its algebraic multiplicity.\n",
    "- The trace of a matrix is the sum of the elements on its main diagonal. The main diagonal of a matrix consists of the elements that run from the top left corner to the bottom right corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.trace(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Dependance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linearly Independent Vectors: If you plot them on a graph, they will point in different directions, and no one vector lies on the line formed by another vector.\n",
    "- Linearly Dependent Vectors: If you plot them, they will lie on the same line, meaning one is just a scaled version of the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "v1 = np.array([1, 2])\n",
    "v2 = np.array([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [2, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack them into a matrix\n",
    "matrix = np.column_stack([v1, v2])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rank of the matrix\n",
    "rank = np.linalg.matrix_rank(matrix)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 and v2 are linearly independent.\n"
     ]
    }
   ],
   "source": [
    "if rank == 2:\n",
    "    print(\"v1 and v2 are linearly independent.\")\n",
    "else:\n",
    "    print(\"v1 and v2 are linearly dependent.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Rank of a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The rank of a matrix is the maximum number of linearly independent columns (or rows) in the matrix.\n",
    "- It tells us the dimension of the column space (or row space) of the matrix, which is the span of its columns (or rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Full Rank: If the rank of the matrix is equal to the number of columns (or rows), the columns (or rows) are linearly independent.\n",
    "2. Less than Full Rank: If the rank is less than the number of columns (or rows), there is linear dependence among the columns (or rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Eigenvalues and Eigenvectors\n",
    "- How does this relate to lambda?\n",
    "- \"The trace is also equal to the sum of the eigenvalues of the matrix\"\n",
    "- Contin. page 269 of LinAlg.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are discriminiative / generative models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are polynomial features and curve / 3rd order etc?\n",
    "- Step over the lab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
