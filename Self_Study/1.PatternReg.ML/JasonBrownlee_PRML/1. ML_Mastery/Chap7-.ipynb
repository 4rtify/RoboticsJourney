{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy\n",
    "import matplotlib as plot\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "filename = 'code\\chapter_04\\pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "indians = read_csv(filename, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer_dataset = load_breast_cancer()\n",
    "cancer = pd.DataFrame(data=cancer_dataset.data, columns=cancer_dataset.feature_names)\n",
    "# cancer['target'] = cancer_dataset.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2579, 85)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ames = pd.read_csv('Ames.csv')\n",
    "print(ames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data\n",
    "- Rescale\n",
    "- Standardize\n",
    "- Normalize \n",
    "- Binarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms\n",
    "1. Load the dataset\n",
    "2. Split into the input and output variables\n",
    "3. Apply pre-processing transform to the input variables\n",
    "4. Summarize the data to show the change\n",
    "\n",
    "- Two methods for data transforming\n",
    "1. Fit and multiple transform\n",
    "2. Combined fit-and-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMaxScaler (Rescale)\n",
    "- Transform / pre-processing tool\n",
    "- If dataset attributes vary significantly - we can rescale all the values between 0 and 1\n",
    "- Referred to as normalization\n",
    "- Good for optimization algorithms like gradient decent;\n",
    "- Also algorithms that weight inputs like regression and neural networks and distance based measures like KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "scalar = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler (Standardize)\n",
    "- StandardScaler is commonly used in algorithms like linear regression, logistic regression, and linear discriminant analysis, which benefit from standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0         1        10       100\n",
      "1         2        20       200\n",
      "2         3        30       300\n",
      "3         4        40       400\n",
      "4         5        50       500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Let's create a sample dataset\n",
    "data = {\n",
    "    'Feature1': [1, 2, 3, 4, 5],\n",
    "    'Feature2': [10, 20, 30, 40, 50],\n",
    "    'Feature3': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0 -1.414214 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107 -0.707107\n",
      "2  0.000000  0.000000  0.000000\n",
      "3  0.707107  0.707107  0.707107\n",
      "4  1.414214  1.414214  1.414214\n",
      "Feature1    1.118034\n",
      "Feature2    1.118034\n",
      "Feature3    1.118034\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_standardized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the standardized data back to a DataFrame\n",
    "df_standardized = pd.DataFrame(df_standardized, columns=df.columns)\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(df_standardized)\n",
    "# Calculating the standard deviation of the standardized data\n",
    "print(df_standardized.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0      0.00      0.00      0.00\n",
      "1      0.25      0.25      0.25\n",
      "2      0.50      0.50      0.50\n",
      "3      0.75      0.75      0.75\n",
      "4      1.00      1.00      1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import set_printoptions\n",
    "set_printoptions(precision=3)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "df_standardized = scaler.fit_transform(df)\n",
    "\n",
    "# Convert the standardized data back to a DataFrame\n",
    "df_standardized = pd.DataFrame(df_standardized, columns=df.columns)\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(df_standardized)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
