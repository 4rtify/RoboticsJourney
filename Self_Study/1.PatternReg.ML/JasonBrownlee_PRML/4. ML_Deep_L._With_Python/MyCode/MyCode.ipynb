{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch and TensorFlow are two major libraries\n",
    "  - TensorFlow developed by Google\n",
    "  - PyTorch is backed by Facebook\n",
    "    - Developed for Python and has the Keras library built-in\n",
    "- Keras wraps the numerical computing complexity of TensorFlow\n",
    "- \"TensorFlow absorbed Keras as part of its library\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backgroud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of some deep learning libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Machine Learning is a board topic\n",
    "- Deep learning, in particular, is a way of using neural networks for machine learning\n",
    "- The concept of a neural network is probably older than machine learning, going back to the 1950s\n",
    "- Below are some famous libraries for neural networks and deep learning\n",
    "  - The differences between PyTorch and TensorFlow\n",
    "- Deep learning has gained attention in the last decade\n",
    "- Before that, there was little confidence is how to train a multilayer perceptron neural network with multiple layers\n",
    "- Before deep learning, we had a neural network library called **libann**\n",
    "- It was a library for C++\n",
    "- One of the earliest libraries for deep learning was Caffe, developed at UC Berkeley for computers vision problems\n",
    "- Developed in C++ but with a Python interface\n",
    "- We can build projects in Python with the network defined in JSON like syntax\n",
    "- Chainer is another Python library, with easy syntax - less common these days but the API in Keras and PyTorch is similar\n",
    "- Theano is another library but now obsolete, but was a major library for deep learning\n",
    "- Earlier versions of Keras allow you to chose between Theano or TensorFlow for the backend\n",
    "  - Neither Theano or TensorFlow are deep learning libraries precisely, rather then are tensor libraries that make matrix operations and differentiation handy\n",
    "  - Where deep learning operations can be built\n",
    "  - Hence Theano and TensorFlow are considered replacements for each other from Keras' perspective\n",
    "- Apache MXNet and Microsoft CNTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch and TensorFlow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The common way of defining a deep learning model is PyTorch is to create a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One major difference between PyTorch and Keras syntax is in the training loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 2 - Intro to TensorFlow\n",
    "- Is it a library created by Google\n",
    "- It allows for fast numerical computing \n",
    "- Foundation library that can be used for deep learning\n",
    "- Or a wrapper library can be used to simply using TensorFlow\n",
    "- This chapter covers:\n",
    "  - About the TensorFlow library\n",
    "  - How to define, compile, and evaluate simple symbolic expressions in TensorFlow\n",
    "- Open-source library for fast numerical computing, created and maintained by Google, released under Apache 2.0 open source license\n",
    "- The API is Python based, but you can access the underlying C++ API\n",
    "- Unlike other deep learning libraries like Theano, TensorFlow is designed for use in Research / Development and for Production systems eg: RankBrain and DeepDream\n",
    "- Can run on PC, GPUs, mobile devices and large scale distributed systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How to install**\n",
    "  - pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **My first example in TensorFlow**\n",
    "- Computation in TensorFlow is described in terms of data flow and operations in the structure of a directed graph\n",
    "- Terms in describing a directed graph:\n",
    "  - **Nodes** : perform computation and can have inputs or outputs. \n",
    "    - Data that moves between nodes are known as **tensors** which are multi-dimensional arrays or real values\n",
    "  - **Edges** : The graphs shows the flow of data, branching, looping and updating. Specials edges can be used to synchronize behavior in the graph. eg: waiting for computation to complete\n",
    "  - **Operation** : An abstract term for computation lol - an add or multiply operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Computation with TensorFlow**\n",
    "  - The below code shows how to define values as **tensors** and execute operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(10)\n",
    "b = tf.constant(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.random.rand(100).astype(np.float32)\n",
    "y_data = X_data * 0.1 + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal([1]))\n",
    "b = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss():\n",
    "    y = W * X_data + b\n",
    "    loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "    return loss   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'minimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5000\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m(mse_loss, var_list\u001b[38;5;241m=\u001b[39m[W,b])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(step, W\u001b[38;5;241m.\u001b[39mnumpy(), b\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'minimize'"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "for step in range(5000):\n",
    "    optimizer.minimize(mse_loss, var_list=[W,b])\n",
    "    if step % 500 == 0:\n",
    "        print(step, W.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1.4301988] [-0.00099999]\n",
      "500 [1.0829537] [-0.19162789]\n",
      "1000 [0.8327605] [-0.07242619]\n",
      "1500 [0.5913301] [0.05106386]\n",
      "2000 [0.3908629] [0.15289497]\n",
      "2500 [0.24704511] [0.22569285]\n",
      "3000 [0.1604788] [0.2694466]\n",
      "3500 [0.11899895] [0.29040247]\n",
      "4000 [0.10420582] [0.29787543]\n",
      "4500 [0.1005907] [0.29970163]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for step in range(5000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Record the operations for gradient computation\n",
    "        loss_value = mse_loss()\n",
    "\n",
    "    # Compute gradients with respect to W and b\n",
    "    gradients = tape.gradient(loss_value, [W, b])\n",
    "\n",
    "    # Apply gradients to variables using the optimizer\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        print(step, W.numpy(), b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 3 - AutoGrad to solve Regression problem\n",
    "- More Gradient Decent aye\n",
    "- TensorFlow is usually used for building neural networks\n",
    "- TensorFlow can also be used as an optimization tool using AutoGrad - more Gradient Decent\n",
    "- TensorFlow is a library with automatic differentiation capability\n",
    "- I can use it to solve numerical optimization problems with GD\n",
    "- This is the algorithm to train neural networks - AutoGrad ....\n",
    "- This chapter covers:\n",
    "  - How TensorFlow's automatic differentiation engine \"AutoGrad\" works.\n",
    "  - How to make use of AutoGrad and an \"optimizer\" to solve an optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGrad in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a constant matrix\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well more like a vector, but apparently similar to numpy vectors\n",
    "x = tf.constant([1,2,3]) # Allows values to be changed\n",
    "# x = tf.Variable([1,2,3]) # Is immutable\n",
    "# !! Import when you run a gradient tape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "(3,)\n",
      "<dtype: 'int32'>\n",
      "tf.Tensor([1 4 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)\n",
    "print(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.6)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x*x\n",
    "dy = tape.gradient(y, x)\n",
    "print(dy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGrad for Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[-1.0751817 ],\n",
      "       [ 1.3354455 ],\n",
      "       [ 0.20098118]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[1.0001751],\n",
      "       [1.9998642],\n",
      "       [2.9871678]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "N = 20\n",
    "polynomial = np.poly1d([1,2,3])\n",
    "X = np.random.uniform(-10, 10, size=(N,1))\n",
    "Y = polynomial(X)\n",
    "XX = np.hstack([X*X, X, np.ones_like(X)])\n",
    "w = tf.Variable(tf.random.normal((3,1))) # The three coefficients\n",
    "x = tf.constant(XX, dtype=tf.float32) # Input sample\n",
    "y = tf.constant(Y, dtype=tf.float32) # Output sample\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "print(w)\n",
    "\n",
    "for _ in range(5000): \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = x @ w\n",
    "        mse = tf.reduce_sum(tf.square(y - y_pred))\n",
    "    grad = tape.gradient(mse, w)\n",
    "    optimizer.apply_gradients([(grad, w)])\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
