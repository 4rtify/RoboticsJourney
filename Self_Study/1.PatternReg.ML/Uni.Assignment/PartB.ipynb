{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Part B\n",
    "#### 11482 - Pattern Recognition and Machine Learning\n",
    "#### James McGuinness (u3196600)\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "Introduce the problem you wish to solve (use the MNIST case as a guide). Explain what questions would you want to ask from the selected dataset?  \n",
    "*(10 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Referring to *LogisticRegression_PRML_MNIST.pdf* from Week 3:\n",
    "  - \"human benchmark for classifying MNIST is about 97.5% accuracy\"\n",
    "- I would like to see if I can score this\n",
    "- Noting this is a different dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/zalando-research/fashionmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Description\n",
    "What do the rows and columns mean and are there any special characteristics in the data to use in modelling the learning?  \n",
    "How would you visualise data to extract patterns to use?  \n",
    "*(5 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Fashion-MNIST dataset contains pictures clothing. \n",
    "- The clothing is from a brand called Zalando. From a brief search online it appears Zalando is a clothing retailer and tech company.\n",
    "- Each picture is 28x28 pixels = 748 pixels\n",
    "- Each row represents an individual piece of clothing \n",
    "- Column 1 is the class label \n",
    "- Columns 2 to 748 are pixel integers, range from 1 to 255. \n",
    "- This is actually a larger dataset than I expected, don't let the simplicity of the pictures fool you lol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression Explanation\n",
    "Why would Logistic Regression suit as the learning model to answer the questions?  \n",
    "Explain why Logistic Regression suits the dataset and problems  \n",
    "*(5 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I guess it's categorical data, so we'll use a classification algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieving data\n",
    "Retrieving data in the program - explain how this is done?  \n",
    "*(5 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I chose to down load the zip file, there are numerous other ways however, I believe this is easy and simple regarding marking purposes and modulation of code.\n",
    "- Download zip folder from https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
    "- Extract the zip file to directory .\\Fashion-MNIST\n",
    "- Run below statements to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('.\\\\Fashion-MNIST\\\\fashion-mnist_train.csv')\n",
    "test = pd.read_csv('.\\\\Fashion-MNIST\\\\fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exploring the data\n",
    "Explain any special adaptation and characteristics  \n",
    "Explore data for patterns and relationships as used in the design  \n",
    "Use visualisation and other relevant statistics measures (as for MNIST).  \n",
    "*(5 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Show image & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'T-shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "train['label'] = train['label'].map(label_mapping)\n",
    "test['label'] = test['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = train['label'].values\n",
    "images = train.drop('label', axis=1).values\n",
    "\n",
    "labels = test['label'].values\n",
    "images = test.drop('label', axis=1).values\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "for idx in range(5):\n",
    "    image = images[idx]\n",
    "    label = labels[idx]\n",
    "    plt.subplot(1, 5, idx + 1)\n",
    "    plt.imshow(image.reshape(28, 28), cmap=plt.cm.gray)\n",
    "    plt.title(f'{label}', fontsize=15)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Show corresponding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train.iloc[1, 1:]).reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Describe & understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build a Logistic Regression Model\n",
    "Explain logistic regression and how it suits the chosen dataset and the problem?  \n",
    "*(6 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\James\\\\Desktop\\\\RoboticsJourney\\\\Self_Study\\\\1.PatternReg.ML\\\\introduction_to_ml_with_python')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Select Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(train)\n",
    "n_samples\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Split data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('label', axis=1)\n",
    "y_train = train['label']\n",
    "\n",
    "X_test = test.drop('label', axis=1)\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - I don't think I need the below statement\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v. Select a linear regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vi. Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a. Scaling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdscaler = StandardScaler()\n",
    "stdscaler.fit(X_train)\n",
    "\n",
    "X_train_stdscaled = stdscaler.transform(X_train)\n",
    "X_test_stdscaled = stdscaler.transform(X_test)\n",
    "\n",
    "logreg.fit(X_train_stdscaled, y_train)\n",
    "logreg.score(X_test_stdscaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler - 47secs with 0.85 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "mm_scaler.fit(X_train)\n",
    "\n",
    "X_train_mm_scaler = mm_scaler.transform(X_train)\n",
    "X_test_mm_scaler = mm_scaler.transform(X_test)\n",
    "\n",
    "logreg.fit(X_train_mm_scaler, y_train)\n",
    "logreg.score(X_test_mm_scaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "norm_scaler = Normalizer()\n",
    "norm_scaler.fit(X_train)\n",
    "\n",
    "X_train_norm_scaler = norm_scaler.transform(X_train)\n",
    "X_test_norm_scaler = norm_scaler.transform(X_test)\n",
    "\n",
    "logreg.fit(X_train_norm_scaler, y_train) \n",
    "logreg.score(X_test_norm_scaler, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Reduction (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "X_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "logreg.fit(X_pca, y_train)\n",
    "logreg.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vii. Prediction of unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7a. Analysis of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Create confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above is actually cool - comparing classes (labels) against how they were classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "cmd = ConfusionMatrixDisplay(confusion, display_labels=class_names)\n",
    "cmd.plot()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Visualise correct predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_and_predictions = list(zip(X_train, logreg.predict(X_train)))\n",
    "# images_and_predictions = list(zip(X_train, y_train))\n",
    "# TODO - strange I don't understand why the above statements are in the lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    image = X_train.iloc[idx,:]\n",
    "    # prediction = logreg.predict(X_train)[idx]\n",
    "    # TODO - also strange that we predict above, but this could also be incorrect?\n",
    "    prediction = y_train[idx]\n",
    "    plt.subplot(1,5,idx+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.array(image).reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %s' % (prediction))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Visualize misclassified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(y_train, y_pred):\n",
    "    # print(f\"{label} ne {predict} = {label != predict}\")    \n",
    "    if label != predict:        \n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,3))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.array(X_train.iloc[badIndex, :]).reshape(28, 28), cmap=plt.cm.gray, interpolation='nearest')\n",
    "    plt.title('Predicted: {},\\n Actual: {}'.format(y_pred[badIndex], np.array(y_train)[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9018"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(misclassifiedIndexes)\n",
    "# for m in misclassifiedIndexes:\n",
    "#     print(f\"{y_pred[m]} + {y_train[m]}\")\n",
    "#     check = y_pred[m] == y_train[m]\n",
    "#     print(check)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Visualize corrected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract misclassified examples and their true labels\n",
    "misclassified_X = np.array(X_test.iloc[misclassifiedIndexes])\n",
    "misclassified_y = np.array(y_test.iloc[misclassifiedIndexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original training set with misclassified examples\n",
    "X_combined = np.vstack((X_train, misclassified_X))\n",
    "y_combined = np.concatenate((y_train, misclassified_y))\n",
    "\n",
    "# Optionally, shuffle the combined dataset to avoid any order bias\n",
    "from sklearn.utils import shuffle\n",
    "X_combined, y_combined = shuffle(X_combined, y_combined, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model again with the new combined training set\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000)  # Increase iterations if needed\n",
    "lr.fit(X_combined, y_combined)\n",
    "\n",
    "# Evaluate the retrained model\n",
    "y_pred_updated = lr.predict(X_test)\n",
    "score_updated = lr.score(X_test, y_test)\n",
    "print(\"Updated score:\", score_updated)\n",
    "\n",
    "# Optional: Recalculate misclassified indexes for new insights\n",
    "misclassifiedIndexes_updated = [index for index, (label, predict) in enumerate(zip(y_test, y_pred_updated)) if label != predict]\n",
    "print(\"Number of misclassified examples:\", len(misclassifiedIndexes_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(confusion, display_labels=class_names)\n",
    "cmd.plot()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred_updated)\n",
    "cmd = ConfusionMatrixDisplay(confusion, display_labels=class_names)\n",
    "cmd.plot()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7b. Analysis of results\n",
    "Explain the classification report and accuracy evaluation.  \n",
    "How might cross-validation be used when training a logistic regression model - use the example to illustrate.  \n",
    "*(10 pts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Regularization \n",
    "Explain the concept of regularization in logistic regression and how does it prevent overfitting?  \n",
    "Explain how can it be used in Fashion-MNIST modelling?  \n",
    "*(5 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Access saved model\n",
    "Save the trained model and explain how you would use it for new unseen data.  \n",
    "How would you access and use it for prediction on new inputs?  \n",
    "(*4 pts*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubric\n",
    "https://uclearn.canberra.edu.au/courses/16042/assignments/129302"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO\n",
    "- ChatGPT\n",
    "- Kaggle\n",
    "- Learning python PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of document**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
